# 论文学习笔记

## pytorch 用法

- torch.nn.Parameter
  
    [理解torch.nn.Parameter](https://zhuanlan.zhihu.com/p/344175147)
    
- torch的数据读取:dataloader
  
    封装关系：Dataset → DataLoader → DataLoaderIt
    
    [Pytorch数据读取(Dataset, DataLoader, DataLoaderIter)](https://zhuanlan.zhihu.com/p/30934236)
    
- torch.Tensor
    - torch.Tensor会调用Tensor类的构造函数__init__，生成单精度浮点类型的张量。
    - torch.tensor & torch.Tensor的对比
      
        [torch.Tensor和torch.tensor的区别_Vic_Hao的博客-CSDN博客_torch.t](https://blog.csdn.net/weixin_42018112/article/details/91383574)
    
- torch.nn.Sequential(*layers)
    - 将每一个模块按照他们的顺序送入到nn.Sequential中 ,输入可以是一些列有顺序的模块
      
        [Pytorch 容器](https://blog.csdn.net/u013548568/article/details/80294708)
        
    - [https://blog.csdn.net/qq_27278957/article/details/120137190](https://blog.csdn.net/qq_27278957/article/details/120137190)
- torch.nn.dropout
    - torch.nn.Dropout(p=0.5, inplace=False)
    - 训练过程中以概率P随机的将参数置0，其中P为置0的概率，例如P=1表示将网络参数全部置0
    - 在训练和测试的时候，`nn.Dropout`的表现是不同的，在训练时`nn.Dropout`会以概率p随机的丢弃一些神经元，但是在测试时，所有神经元都不会被丢弃
    - 
      
        [](http://t.csdn.cn/8Z9AO)
    
- torch.nn.BatchNorm1d
    - BatchNorm就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的
    - num_features就是你需要归一化的那一维的维度
- 优化器optimizer
    - Adam优化器
    
    [通俗理解 Adam 优化器](https://zhuanlan.zhihu.com/p/377968342)
    
- 梯度下降：
    - 这三个函数的作用是先将梯度归零（optimizer.zero_grad()）
    - 然后反向传播计算得到每个参数的梯度值（loss.backward()）
    - 最后通过梯度下降执行一步参数更新（optimizer.step()）
    - [https://flyswiftai.com/li-jieoptimizerzerograd-lossbackward-opt/](https://flyswiftai.com/li-jieoptimizerzerograd-lossbackward-opt/)
- torch.nn.functional.softplus
    - 公式如下：
    
    ![Untitled](pic/Untitled0.png)
    

## numpy用法

- np.argsort
    - argsort函数返回的是数组值从小到大的索引值
    
    ![Untitled](pic/Untitled%201.png)
    

## 其他知识

- pytorch和tensorflow对比：
  
    1、具有强大的GPU加速的张量计算（如NumPy）
    
    2、包含自动求导系统的的深度神经网络
    
    3、动态图机制
    
- 推荐系统评价指标：NDCG，Recall
    - Recall：在正样本中有多少被预测为真
    - NDCG：归一化折损累计增益：对DCG进行标准化的方式是对其处以IDCG
    - 标准化后得到的NDCG是一个相对值，从而使得即使不同的用户之间可以进行比较
    - 知乎帖子：
    
    [推荐系统中的常用评价指标：NDCG，Recall，AUC，GAUC](https://zhuanlan.zhihu.com/p/431704675)
    
- BPRLoss
    - 它是基于Bayesian Personalized Ranking。BPR Loss 的思想很简单，就是让正样本和负样本的得分之差尽可能达到最大。具体公式如下：
    - 公式：
    
    ![Untitled](pic/Untitled%202.png)
    

